#!/usr/bin/env python
"""
Author:
Shalabh Thakur
Sycuro Lab, University of Calgary
12/10/2017

Description:
This is a script to run minimus2 on set of genomes. 
Currently it is only a test script to run minimus2 on all genomes in a single directory.
Input will be directory containing multi-fasta contig files to be combined using minimus2

"""
import sys
import os
import glob
import argparse
import re
import shutil
import logging
import datetime
from argparse import RawTextHelpFormatter
from Bio import SeqIO


def parse_args(desc):

	"""
	Function to read & parse command-line parameters.
	
	:param desc: Short program description.
	:type desc: str
	
	:return arg: dict of command line arguments with key=command line
        argument and val=argument value
        
    :return_type: dict
    """
	parser = argparse.ArgumentParser(description=desc, formatter_class=RawTextHelpFormatter)
	parser._optionals.title="Arguments"
	parser.add_argument("-i", "--input_dir", required=True, 
                        help="Path to the genome directory containing multi-fasta contig files to merge (Mandatory)\n")
	parser.add_argument("-o", "--output_dir", required=True,
                        help="Path to the directory to store output from the minimus2 run (Mandatory)\n")
	parser.add_argument("-n", "--name", default="MM2_combined_assemblied",
						help="Name of the job run (Mandatory)\n")
	
	parser.add_argument("--merge_assemblies", type=int, choices=[1, 2], default=1,
    					help="1: Combine assemblies starting with longest assembly as a reference (Default)\n"
    						 "2: Combine assemblies starting with shortest assembly as a reference\n")
	 
	parser.add_argument("--choose_ref_assembly", default=1, type=int, choices=[1, 2],
						help="1: Choose reference assembly based on total sequence length (Default)\n"
						     "2: Choose reference assembly based on N50 value\n")
	parser.add_argument("--all_vs_all", action="store_true", default=False,
						help="Run Minimus2 in all-vs-all mode if True. By default, run Minimus2 by comparing reference to query\n")
	parser.add_argument("--prefix", default="Merged_MM2",
						help="Prefix to add to output files generated by running amos and minimus2\n")
	parser.add_argument("--overlap", default=40, type=int, 
						help="Minimus2 parameter to provide minimum basepair overlap between assemblies (Default 40bp)\n")
	parser.add_argument("--minid", default=94, type=float, choices=range(1, 100), metavar="[1-100]", 
						help="Minimus2 parameter to minimum overlap percent identity for alignments [1..100] (Default 94)\n")
	parser.add_argument("--conserr", default=0.06, type=float, choices=range(0, 1), metavar="[0-1]", help="Minimus2 parameter to maximum consensus error [0..1] (Default 0.06)\n")
	parser.add_argument("--maxtrim", default=20, type=int, 
						help="Minimus2 parameter to maximum sequence trimming length (Default 20bp)\n")
						
						
	args=parser.parse_args()
    
	return vars(args)
    

def main():

	"""
	Main Function 
	"""
	now = datetime.datetime.now()
	
	c_args = parse_args(__file__)
	indir=os.path.abspath(c_args['input_dir'])
	outdir=os.path.abspath(c_args['output_dir'])
	
	#### get absolute path of output dir and make dir####
	output_dir=os.path.abspath(c_args['output_dir'])
	if not os.path.exists(output_dir):
		os.makedirs(output_dir)
	
	####### Create a run-log file ####
	logging.basicConfig(filename=os.path.join(output_dir,"multiminimus2-run.log"),level=logging.DEBUG)
	logging.info("This is a log file for multiminimus2 program executed on {} %Y-%m-%d %H:%M\n".format(now.strftime))
	logging.info("[STEP1]: RUNNING COMMAND: python multiminimus.py\n")
	logging.info("[PARAMETERS]\n")
	
	#### Log command-line parameters #####
	for index,cmd_arg in enumerate(c_args):
		if index==len(c_args)-1:
			logging.info("[{}]: {}\n".format(cmd_arg.upper(),str(c_args[cmd_arg])))
		else:
			logging.info("[{}]: {}".format(cmd_arg.upper(),str(c_args[cmd_arg])))
			
	##### Read file names for the input directory
	logging.info("[STEP2]: READ INPUT DIRECTORY: {}\n".format(indir))
	if os.path.exists(indir):
		list_infile=get_file_names_from_dir(indir)
	else:
		logging.debug("[INVALID DIRECTORY PATH!!!]: Cannot open or no such directory {}\n".format(indir))
		
	#### declare dict for storing assembly stats where key is file name and value is dict assembly_statistics
	logging.info("[STEP3]: CALCULATING ASSEMBLY STATISTICS\n")
	assembly_stats={}
	
	for file_name in list_infile:
	
		#### Prepare file path for assembly####
		file_path=indir+"/"+file_name
		assembly_name=re.sub(r'(\.\w+)','',file_name)
		
		#### calculate assembly statistics for each file and store in dict assembly_statistics ###
		### where key are assembly attributes and value is statistics ###
		assembly_statistics=calculate_assembly_stats(file_path)
		#### add dict assembly_statistics to dict assembly_stats where key is a file name of an assembly
		assembly_stats[assembly_name]=assembly_statistics
	    #### assembly dictionary to store total assembly length or N50 value ####
	    #### if choose_ref_assembly=1 then assembly_dict stores total assembly length ###
	    #### else-if choose_ref_Assembly=2 then assembly_dict store N50 value ####
		assembly_dict={}
	    
	#### Test loop to print assembly stats for each assembly file ####	
	for assembly_name in assembly_stats:
        ### loop through dict assembly_stats
		stats=assembly_stats[assembly_name]
		logging.info("[ASSEMBLY NAME]: {}".format(assembly_name))
		logging.info("[FILE_PATH]: {}".format(str(stats['file_path'])))
		logging.info("[NUM_SEQ]: {}".format(str(stats['num_seq'])))
		logging.info("[TOTAL_LENGTH]: {}".format(str(stats['total_length'])))
		logging.info("[MAX_SEQ_LENGTH]: {}".format(str(stats['max_seq_length'])))
		logging.info("[MIN_SEQ_LENGTH] {}:".format(str(stats['min_seq_length'])))
		logging.info("[AVG_SEQ_LENGTH]: {}".format(str(stats['avg_seq_length'])))
		logging.info("[N50_VALUE]: {}".format(str(stats['n50_value'])))
		logging.info("[N_COUNT]: {}".format(str(stats['n_count'])+"\n"))

		#### if --choose_ref_assembly=1 choose assembly based on total assembly length ###
		if c_args['choose_ref_assembly']==1:
			assembly_dict[assembly_name]=stats['total_length']	
		elif c_args['choose_ref_assembly']==2: 
		#### if --choose_ref_assembly=2 choose assembly based on N50 value ###  
			assembly_dict[assembly_name]=stats['n50_value']

	#### Sorted array of assembly by length or N50 ###
	sorted_assembly=[]
		#### if --merge assembly=1 choose assembly with maximum value ###
	if c_args['merge_assemblies']==1:
	#ref_assembly=max(assembly_dict, key=assembly_dict.get)
		logging.info("[STEP 4]: CHOOSING REFERENCE ASSEMBLY BASED ON LONGEST ASSEMBLY\n")
		sorted_assembly=sorted(assembly_dict.items(), key =lambda t:t[1], reverse=True)
	else:
	#### if --merge assembly=2 choose assembly with minimum value ###		
	#ref_assembly=min(assembly_dict, key=assembly_dict.get)
		logging.info("[STEP 4]: CHOOSING REFERENCE ASSEMBLY BASED ON SHORTEST ASSEMBLY\n")
		sorted_assembly=sorted(assembly_dict.items(), key =lambda t:t[1])

	ref_assembly=sorted_assembly[0][0]
	ref_path=assembly_stats[ref_assembly]['file_path']
			
	if c_args['all_vs_all']:
		ref_count=0
	else:
		ref_count=assembly_stats[ref_assembly]['num_seq']

	logging.info("[INITIAL REFERENCE ASSEMBLY]: {}".format(ref_assembly))
	logging.info("[INITIAL REFCOUNT]: {}\n".format(str(ref_count)))
	
	logging.info("[STEP 5]: START COMBINING ASSEMBLIES\n")
	
	header_index=1
	fixed_ref_headers,ref_header_dict,ref_header2index_dict=fix_headers(ref_assembly,ref_path,header_index,singleton=False,header_tag=None)
	
	##### Combine assemblies in order as stored in array sorted_assembly ###
	
	combine_assemblies(assembly_stats, sorted_assembly,ref_assembly,ref_path,ref_count,fixed_ref_headers,ref_header_dict,ref_header2index_dict,output_dir, c_args)
		
		
		
### This function iteratively prepare files for amos and minimus2 run ###		
def combine_assemblies(assembly_stats,sorted_assembly,ref_assembly,ref_path,ref_count,fixed_ref_headers,ref_header_dict,ref_header2index_dict,output_dir, c_args):
	"""
	Input: assembly stats dictonary
	Input: assembly (length pr N50) dictonary
	Input: command-line argument dictonary
	"""
	compiled_result={}
	singleton_path=""
	fixed_singleton_headers=list()
	singleton_header_dic={}
	
	for index, assembly in enumerate(sorted_assembly):
		#### Get name and absolute path of query assembly ###
		if index!=0:
			query_assembly=assembly[0]
			query_path=assembly_stats[query_assembly]['file_path']
			query_index=index
			print (ref_assembly)
			print (query_assembly)
			
			#### fix header for the query assembly ####
			header_index=len(fixed_ref_headers) + 1
			fixed_query_headers,query_header_dict,query_header2index_dict=fix_headers(query_assembly,query_path,header_index,singleton=False,header_tag=None)
			
			if os.path.exists(singleton_path):
				header_index=len(fixed_query_headers) + 1
				fixed_singleton_headers,singleton_header_dict,singleton_header2index_dict=fix_headers(prefix,singleton_path,header_index,singleton=True,header_tag=None)
			
			logging.info("PREPARING FOR COMBINING REFERENCE ASSEMBLY: {} AND QUERY ASSEMBLY: {}".format(ref_assembly,query_assembly))
			#### prepare prefix name for output files for the current iteration ###
			prefix=c_args['prefix']+"_iteration_"+str(query_index)
			base_dir=os.getcwd()
			logging.info("CREATED PREFIX: {}".format(prefix))
			
			#### create sub-directory in output dir for the current iteration ###
			sub_output_dir=output_dir+"/"+prefix
			if not os.path.exists(sub_output_dir):
				os.makedirs(sub_output_dir)
				logging.info("CREATED OUTPUT DIRECTORY: {}".format(sub_output_dir))
			
			#### Write records with fixed header to merged fasta file ####
			#### prepare name for toAmos output file for the current iteration
			merged_assembly_toamos_input_file=sub_output_dir+"/"+prefix+".seq"
			afg_toamos_output_file=sub_output_dir+"/"+prefix+".afg"
			toAmos_run_log=sub_output_dir+"/"+prefix+"_toAmos_run.log"
			
			toamos_input_destination=open(merged_assembly_toamos_input_file,'w')
			SeqIO.write(fixed_ref_headers + fixed_query_headers + fixed_singleton_headers, merged_assembly_toamos_input_file, "fasta")
			toamos_input_destination.close()
			logging.info("MERGED SEQEUNCES FROM REFERENCE AND QUERY ASSEMBLY AND PRINTING TO: {}".format(merged_assembly_toamos_input_file))
			
			#### Call function to run Amos program and generate amos formated genome file (afg) ####
			logging.info("RUNNING AMOS ON MERGED MULTI-FASTA FILE")
			run_Amos(prefix,ref_count,merged_assembly_toamos_input_file,afg_toamos_output_file,toAmos_run_log,sub_output_dir,base_dir)
			
			#### Call function to parse the files in the output directory of current iteration ####
			logging.info("PARSING OUTPUT DIRECTORY: {}".format(sub_output_dir))
			current_iteration_result=parse_iterative_output(prefix,sub_output_dir)
			compiled_result[prefix]=current_iteration_result
			
			##### Mapping headers from original reference and query assembly in combined assembly fasta ####
			##### Replace numerical headers in combined assembly fasta obtained from most recent iteration of minimus2 ###
			logging.info("MAPPING ORIGINAL SEQUENCE HEADERS BACK ON TO THE COMBINED ASSEMBLY AND PRINTING ASSEMBLY TO: {}\n".format(os.path.join(sub_output_dir,"{}.header_mapped.fasta".format(prefix))))
			
			mapped_headers_combined=map_original_headers(current_iteration_result["COMBINED_FILE"],ref_header_dict,ref_header2index_dict,query_header_dict,query_header2index_dict,singleton=False)
			combined_mapped_header_fasta=open(os.path.join(sub_output_dir,"{}.header_mapped_combined.fasta".format(prefix)),'w')
			SeqIO.write(mapped_headers_combined,combined_mapped_header_fasta,"fasta")
			combined_mapped_header_fasta.close()
			
			header_index=1
			
			ref_path=os.path.join(sub_output_dir,"{}.header_mapped_combined.fasta".format(prefix))
			ref_assembly=prefix
			ref_count=current_iteration_result["NUM_SEQ_COMBINED"]
			singleton_path=current_iteration_result["SINGLETON_FILE"]
			mapped_headers_singleton=map_original_headers(singleton_path,ref_header_dict,ref_header2index_dict,query_header_dict,query_header2index_dict,singleton=True)

			
			fixed_ref_headers,ref_header_dict,ref_header2index_dict=fix_headers(ref_assembly,ref_path,header_index,singleton=False,header_tag=None)
	
	compiled_result_log_file=open(os.path.join(output_dir,"{}.result.log".format(c_args["name"])),'w')
			
	logging.info("PRINTING COMPILED RESULT FOR {} INTO RESULT FILE {}".format(c_args["name"],compiled_result_log_file))
	
	compiled_result_log_file.write("PREFIX\tMERGED_FILE\tCOMBINED_FILE\tSINGLETON_FILE\tNUM_SEQ_MERGED\tLENGTH_SEQ_MERGED\t"
	                               "NUM_SEQ_REF\tLENGTH_SEQ_REF\tNUM_SEQ_QUERY\tLENGTH_SEQ_QUERY\tNUM_SEQ_COMBINED\tLENGTH_SEQ_COMBINED\t"
	                               "NUM_SEQ_SINGLETON\tLENGTH_SEQ_SINGLETON\n")
	
	for prefix in compiled_result:
		
		iteration_result=compiled_result[prefix]
		
		compiled_result_log_file.write("{}\t{}\t{}\t{}\t{}\t{}\t{}\t{}\t{}\t{}\t{}\t{}\t{}\t{}\n".format(iteration_result["PREFIX"],iteration_result["MERGED_FILE"],iteration_result["COMBINED_FILE"],iteration_result["SINGLETON_FILE"],
		                            	iteration_result["NUM_SEQ_MERGED"],iteration_result["LENGTH_SEQ_MERGED"],iteration_result["NUM_SEQ_REF"],iteration_result["LENGTH_SEQ_REF"],
		                                iteration_result["NUM_SEQ_QUERY"],iteration_result["LENGTH_SEQ_QUERY"],iteration_result["NUM_SEQ_COMBINED"],iteration_result["LENGTH_SEQ_COMBINED"],
	                               		iteration_result["NUM_SEQ_SINGLETON"],iteration_result["LENGTH_SEQ_SINGLETON"]))
	compiled_result_log_file.close()
		

def map_original_headers(assembly_path,ref_header_dict,ref_header2index_dict,query_header_dict,query_header2index_dict,singleton=False):

	"""
	Takes path to the combined fasta file and map the orignal header from query and reference assemblies
	replacing the numerical headers given by Amos
	"""
	mapped_headers=list()
	
	with open(assembly_path,"r") as assembly:
		seq_records=SeqIO.parse(assembly, "fasta")
	
		for record in seq_records:
			if singleton:
				if record.id in ref_header2index_dict:
					print record.id,"REFERENCE"
				elif record.id in query_header2index_dict:
					print record.id,"QUERY"
			else:
				if int(record.id) in ref_header_dict:
					record.id=ref_header_dict[int(record.id)]
				elif int(record.id) in query_header_dict:
					record.id=query_header_dict[int(record.id)]

				mapped_headers.append(record)

	return(mapped_headers)
	
	
###### This function parse files in the output directory generated for each iteration ####
def parse_iterative_output(prefix,sub_output_dir):

	"""
	Takes prefix name and path of sub-output directory for the current iteration to parse and gather 
	information for the run.
	:param prefix: prefix name used to prepend with output files in the most recent run
	:type: str
	:param header_index_dict: dictonary of header index as a key and header name as a value
	:type: dict
	:param sub_output_dir: directory path for the output folder which stores result files from most recent run of Amos.
	:type: str
	"""
	result={}
	
	merged_fasta_file_path=os.path.join(sub_output_dir,prefix+".seq")
	reference_fasta_file_path=os.path.join(sub_output_dir,prefix+".ref.seq")
	query_fasta_file_path=os.path.join(sub_output_dir,prefix+".qry.seq")
	combined_fasta_file_path=os.path.join(sub_output_dir,prefix+".fasta")
	singleton_fasta_file_path=os.path.join(sub_output_dir,prefix+".singletons.seq")
	
	stats_merged_fasta_file=calculate_assembly_stats(merged_fasta_file_path)
	stats_reference_fasta_file=calculate_assembly_stats(reference_fasta_file_path)
	stats_query_fasta_file=calculate_assembly_stats(query_fasta_file_path)
	stats_combined_fasta_file=calculate_assembly_stats(combined_fasta_file_path)
	stats_singleton_fasta_file=calculate_assembly_stats(singleton_fasta_file_path)
	
	result["PREFIX"]=prefix
	result["NUM_SEQ_REF"]=stats_reference_fasta_file["num_seq"]
	result["LENGTH_SEQ_REF"]=stats_reference_fasta_file["total_length"]
	result["NUM_SEQ_QUERY"]=stats_query_fasta_file["num_seq"]
	result["LENGTH_SEQ_QUERY"]=stats_query_fasta_file["total_length"]
	result["NUM_SEQ_MERGED"]=stats_merged_fasta_file["num_seq"]
	result["LENGTH_SEQ_MERGED"]=stats_merged_fasta_file["total_length"]
	result["NUM_SEQ_COMBINED"]=stats_combined_fasta_file["num_seq"]
	result["LENGTH_SEQ_COMBINED"]=stats_combined_fasta_file["total_length"]
	result["NUM_SEQ_SINGLETON"]=stats_singleton_fasta_file["num_seq"]
	result["LENGTH_SEQ_SINGLETON"]=stats_singleton_fasta_file["total_length"]
	result["MERGED_FILE"]=merged_fasta_file_path
	result["COMBINED_FILE"]=combined_fasta_file_path
	result["SINGLETON_FILE"]=singleton_fasta_file_path
	
	logging.info("PRINTING RESULTS FOR {} INTO RESULT FILE {}".format(prefix,os.path.join(sub_output_dir,prefix+".result.log")))
	
	result_log_file=open(os.path.join(sub_output_dir,prefix+".result.log"),'w')
	result_log_file.write("[{}]: {}\n".format("PREFIX", result["PREFIX"]))
	result_log_file.write("[{}]: {}\n".format("MERGED_FILE", result["MERGED_FILE"]))
	result_log_file.write("[{}]: {}\n".format("COMBINED_FILE", result["COMBINED_FILE"]))
	result_log_file.write("[{}]: {}\n".format("SINGLETON_FILE", result["SINGLETON_FILE"]))
	result_log_file.write("[{}]: {}\n".format("NUM_SEQ_MERGED", result["NUM_SEQ_MERGED"]))
	result_log_file.write("[{}]: {}\n".format("LENGTH_SEQ_MERGED", result["LENGTH_SEQ_MERGED"]))
	result_log_file.write("[{}]: {}\n".format("NUM_SEQ_REF", result["NUM_SEQ_REF"]))
	result_log_file.write("[{}]: {}\n".format("LENGTH_SEQ_REF", result["LENGTH_SEQ_REF"]))
	result_log_file.write("[{}]: {}\n".format("NUM_SEQ_QUERY", result["NUM_SEQ_QUERY"]))
	result_log_file.write("[{}]: {}\n".format("NUM_SEQ_COMBINED", result["NUM_SEQ_COMBINED"]))
	result_log_file.write("[{}]: {}\n".format("LENGTH_SEQ_COMBINED", result["LENGTH_SEQ_COMBINED"]))
	result_log_file.write("[{}]: {}\n".format("NUM_SEQ_SINGLETON", result["NUM_SEQ_SINGLETON"]))
	result_log_file.write("[{}]: {}\n".format("LENGTH_SEQ_SINGLETON", result["LENGTH_SEQ_SINGLETON"]))
	result_log_file.close()
	
	return(result)

### This function run minimus2 and amos programs to combine assemblies in a sorted order ###
def run_Amos(prefix,ref_count,merged_assembly_toamos_input_file,afg_toamos_output_file,toAmos_run_log,sub_output_dir,base_dir):
	
	##### Run toAmos command #####
	logging.info("RUNNING TOAMOS PROGRAM")
	logging.info("[TOAMOS_INPUT]:"+merged_assembly_toamos_input_file)
	logging.info("[TOAMOS_OUTPUT]:"+afg_toamos_output_file)
	logging.info("[TOAMOS_LOG]:"+toAmos_run_log)
	
	os.system("toAmos -s "+merged_assembly_toamos_input_file+" -o "+afg_toamos_output_file+" > "+toAmos_run_log)
	os.chdir(sub_output_dir)
	
	logging.info("RUNNING MINIMUS2 PROGRAM")
	logging.info("[MINIMUS2_PREFIX]:"+prefix)
	logging.info("[MINIMUS2_REFCOUNT]:"+str(ref_count))
	logging.info("[MINIMUS2_OUTDIR]:"+sub_output_dir)
	logging.info("[MINIMUS2_LOG]:"+sub_output_dir+"/"+prefix+".runAmos.log")
	
	os.system("minimus2 "+prefix+" -D REFCOUNT="+str(ref_count))
	os.chdir(base_dir)
	

def fix_headers(assembly_name,assembly_path,header_index,singleton=False,header_tag=None,):

	"""
	Take the assembly name and assembly path as an input and associate metainformation with the header
	of the sequences.
	:param assembly_name: name of an assembly file without including file extension.
	:type: str
	:param assembly_path: Absolute file path of the assembly file.
	:type: str
	:param header_tag: Tag to add to the header. If header_tag=None, assembly_name is used as a default value for header_tag.
	:type: str
	:param fixed_header_records: List of sequence records with modified headers
	:type: list
	:param header_index_dict: Dictonary of header as index as a key and header name as a value
	:type: dict
	:param add_seq_length: Whether or not to add length of the sequence to the header.
	:type: boolean
	"""
	fixed_header_records=list()
	header_index_dict={}
	new2old_header_dict={}
	
	with open(assembly_path,"r") as assembly:
		seq_records=SeqIO.parse(assembly, "fasta")
	
		for record in seq_records:
			header_index_dict[header_index]=record.id
			if header_tag:
				record.id="{}_{}_seq_length_{}_seq_index_{}".format(record.id,header_tag,len(record.seq),header_index)
			elif singleton:
				record.id="{}".format(record.id)
			else:
				record.id="{}_{}_seq_length_{}_seq_index_{}".format(record.id,assembly_name,len(record.seq),header_index)
			
			fixed_header_records.append(record)
			new2old_header_dict[record.id]=header_index
			header_index+=1

	return(fixed_header_records,header_index_dict,new2old_header_dict)
	
			
#### This function calculate assembly statistics ####
def calculate_assembly_stats(file_path):

	"""
	Input: file path
	Output: dictonary of assembly statistics
	Calculate assembly-stats for an assembly:
	(1) Total assembly length.
	(2) Number of contigs.
	(3) Average contig length.
	(4) Maximum contig length.
	(5) Minimus contig length.
	(6) N50 value
	(7) N counts.
	(8) File path
	"""
	#### declare variables for assembly stats ######
	total_assembly_length=0
	n50_value=0
	num_seq=0
	avg_seq_length=0
	max_seq_length=0
	min_seq_length=0
	n_count=0
	check_sum=0
	n50_threshold=0
	#### list of sequence length ####
	list_seq_length=list()
	#### dict of assembly stats
	assembly_stats={}
	
	##### loop through each sequence record in the fasta file ###
	for seq_record in SeqIO.parse(file_path, "fasta"):
	    ##### sum of length for each sequence ####
		total_assembly_length +=len(seq_record.seq)
		##### count number of sequences ###
		num_seq +=1
		##### count number of N's in the sequence and sum it to total ###
		n_count += seq_record.seq.upper().count('N')
		##### add sequence length for each contig in an assembly to the list ###
		list_seq_length.append(len(seq_record.seq))
		
	### calculate maximum contig length ###
	max_seq_length=max(list_seq_length)
	### calculate minimum contig length
	min_seq_length=min(list_seq_length)
	### calculate average contig length ###
	avg_seq_length=float(total_assembly_length/num_seq)
	### calculate threshold for n50 calculation ###
	n50_threshold=total_assembly_length/2
	### sort sequence length from highest to lowest ###
	list_seq_length.sort()
	
	### loop through list of sequence length ###
	for seq_length in (list_seq_length):
		#### check sum is sum of sequence length till the total become greater or equal to n50_threshold ###
		check_sum += seq_length
		#### if check sum is greater or equal to n50_threshold then seq_length of current contig is equal to N50 value ###
		if check_sum >= n50_threshold:
			n50_value=seq_length
			break	
			
	### store each assembly statistics in assembly_stats dict ###
	assembly_stats["file_path"]=os.path.abspath(file_path)		
	assembly_stats["total_length"]=total_assembly_length
	assembly_stats["num_seq"]=num_seq
	assembly_stats["max_seq_length"]=max_seq_length
	assembly_stats["min_seq_length"]=min_seq_length
	assembly_stats["avg_seq_length"]=avg_seq_length
	assembly_stats["n50_value"]=n50_value
	assembly_stats["n_count"]=n_count
	
	return(assembly_stats)


##### This function read file names from the directory #######
def get_file_names_from_dir(a_dir):
	"""
	Input: directory name
	"""
	return [name for name in os.listdir(a_dir)
		if os.path.isfile(os.path.join(a_dir, name))]
	


if __name__ == '__main__':
	main()

	
                                          
                           
	

    
                                                  
                                
    
    
    




